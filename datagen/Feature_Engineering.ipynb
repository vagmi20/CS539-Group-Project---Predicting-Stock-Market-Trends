{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Yfb_VPF-oHq7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKeN_iuWtogl",
        "outputId": "657e90be-4aa9-47ab-e913-cb02463e4ef0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stocks = ['AAPL', 'META', 'NVDA']\n",
        "related_terms = {\n",
        "    'AAPL': ['AAPL', 'Apple'],\n",
        "    'META': ['META', 'Metaverse'],\n",
        "    'NVDA': ['NVDA', 'NVIDIA'],\n",
        "}\n",
        "# company url names for Investing.com\n",
        "url_names = {\n",
        "    'AAPL': 'apple-computer-inc',\n",
        "    'META': 'facebook-inc',\n",
        "    'NVDA': 'nvidia-corp',\n",
        "}\n",
        "start = \"2022-01-01\"\n",
        "end = \"2024-01-01\""
      ],
      "metadata": {
        "id": "J8j5Yk8QE5mf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_sentiment_cnt_features(sentiment_df):\n",
        "    # count the number of neutral, pos, neg, articles per day\n",
        "    daily_sentiment_cnt = sentiment_df.groupby('published date')['sentiment_score'].value_counts().unstack(-1).reset_index()\n",
        "    daily_sentiment_cnt.rename(columns={0: 'neg_sentiment_cnt',\n",
        "                                        1: 'neu_sentiment_cnt',\n",
        "                                        2: 'pos_sentiment_cnt'}, inplace=True)\n",
        "    daily_sentiment_cnt.fillna(0, inplace=True)\n",
        "    return daily_sentiment_cnt\n",
        "\n",
        "def generate_sentiment_prob_features(sentiment_df):\n",
        "    # compute average neutral, pos, neg probs across all articles\n",
        "    daily_sentiment_mean_probs = sentiment_df.groupby('published date')[['neg_sentiment_prob', 'neu_sentiment_prob', 'pos_sentiment_prob']].mean()\n",
        "    daily_sentiment_mean_probs.reset_index(inplace=True)\n",
        "    daily_sentiment_mean_probs.rename(columns={'neg_sentiment_prob': 'mean_neg_sentiment_prob',\n",
        "                                              'neu_sentiment_prob': 'mean_neu_sentiment_prob',\n",
        "                                              'pos_sentiment_prob': 'mean_pos_sentiment_prob'}, inplace=True)\n",
        "    return daily_sentiment_mean_probs\n",
        "\n",
        "def generate_sentiment_features(sentiment_df):\n",
        "    # # Convert 'publishedAt' to datetime and set index\n",
        "    # sentiment_df['publishedAt'] = pd.to_datetime(sentiment_df['publishedAt']).dt.tz_localize(None)\n",
        "    # sentiment_df['publishedAt_date'] = sentiment_df['publishedAt'].dt.date\n",
        "\n",
        "    # separate sentiment_probs list into three columns for each sentiment (neg, neutral, pos)\n",
        "    sentiment_df['neg_sentiment_prob'] = sentiment_df['sentiment_probs'].apply(\n",
        "        lambda x: float(x.replace('[','').replace(']','').strip().split(',')[0])\n",
        "    )\n",
        "    sentiment_df['neu_sentiment_prob'] = sentiment_df['sentiment_probs'].apply(\n",
        "        lambda x: float(x.replace('[','').replace(']','').strip().split(',')[1])\n",
        "    )\n",
        "    sentiment_df['pos_sentiment_prob'] = sentiment_df['sentiment_probs'].apply(\n",
        "        lambda x: float(x.replace('[','').replace(']','').strip().split(',')[2])\n",
        "    )\n",
        "    daily_sentiment_cnt = generate_sentiment_cnt_features(sentiment_df)\n",
        "    daily_sentiment_mean_probs = generate_sentiment_prob_features(sentiment_df)\n",
        "    daily_sentiment_features = daily_sentiment_cnt.set_index('published date').join(daily_sentiment_mean_probs.set_index('published date'))\n",
        "    return daily_sentiment_features"
      ],
      "metadata": {
        "id": "nil1tEP6zyjd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for stock in stocks:\n",
        "    # create sentiment features\n",
        "    csv = f\"/content/drive/My Drive/WPI/Senior Year/CS539 (ML)/{stock}_sentiment.csv\"\n",
        "    df = pd.read_csv(csv)\n",
        "    print(len(df))\n",
        "    print(len(df[df.duplicated(['title']) == True]))\n",
        "    df = df.drop_duplicates(['title'])\n",
        "    df = df.dropna()\n",
        "    print(len(df))\n",
        "    sentiment_df = generate_sentiment_features(df)\n",
        "    # print(sentiment_df.head(3))\n",
        "\n",
        "    # load stock data\n",
        "    csv = f\"/content/drive/My Drive/WPI/Senior Year/CS539 (ML)/{stock}_stock.csv\"\n",
        "    stock_df = pd.read_csv(csv)\n",
        "\n",
        "    # prepare join\n",
        "    sentiment_df = sentiment_df.reset_index().rename(columns={'published date': 'Date'})\n",
        "    merged_df = pd.merge(stock_df, sentiment_df, on=['Date'])\n",
        "    print(len(merged_df))\n",
        "\n",
        "    merged_df.to_csv(f\"/content/drive/My Drive/WPI/Senior Year/CS539 (ML)/{stock}_stock_with_sentiment.csv\", index=False)\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "XE-B07bLEU3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "960a08a3-4594-4638-8cab-6e803497bccb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3224\n",
            "1076\n",
            "2104\n",
            "488\n"
          ]
        }
      ]
    }
  ]
}