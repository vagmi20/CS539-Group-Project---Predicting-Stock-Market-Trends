{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "id": "rDDrAC2f2nWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")"
      ],
      "metadata": {
        "id": "dhRsd1-f9YiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dml4rX1c2I1L"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib3\n",
        "\n",
        "!pip show urllib3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUXG8RdoEgB2",
        "outputId": "6cbd762d-3f47-4501-f93d-fc66691e574f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility for Webscraping and Sentiment Analysis"
      ],
      "metadata": {
        "id": "0rttMmqbEyHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_article_text(url, title):\n",
        "    # scrape content\n",
        "    try: # attempt to request page from url\n",
        "        html = urllib3.request(\"GET\", url).data\n",
        "        soup = BeautifulSoup(html, \"html.parser\") # parser for html code\n",
        "\n",
        "        if \"https://news.google.com\" in url:\n",
        "            redirected_url = soup.find('a')['href']\n",
        "\n",
        "            # Make another HTTP GET request to the extracted link\n",
        "            resp = urllib3.request(\"GET\", redirected_url)\n",
        "            html = resp.data\n",
        "            soup = BeautifulSoup(html, \"html.parser\") # parser for html code\n",
        "\n",
        "        text = title + \" \" # text to be appended\n",
        "\n",
        "        # get paragraph text next\n",
        "        p_arr = soup.find_all('p') # get array of all p tag html elements in article\n",
        "        for p in p_arr:\n",
        "            text += p.get_text()\n",
        "        return text\n",
        "    except:\n",
        "        print(f\"Could not open page: {url}\")\n",
        "        return None\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "def get_sentiment_results(df):\n",
        "    sentiment_scores = []\n",
        "    sentiment_probs = []\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        article_text = get_article_text(row['url'],\n",
        "                                        row['title'])\n",
        "        if article_text:\n",
        "            # Combine title and text if available\n",
        "            text = article_text\n",
        "            # Perform sentiment analysis\n",
        "            inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            outputs = model(**inputs)\n",
        "            probs = torch.softmax(outputs.logits, dim=-1)\n",
        "            score = probs.argmax(dim=-1).item()\n",
        "            probs = probs.detach().cpu().numpy().tolist()\n",
        "            sentiment_scores.append(score)\n",
        "            sentiment_probs.append(probs)\n",
        "        else:\n",
        "            # Handle cases where the article could not be fetched or text is missing\n",
        "            sentiment_scores.append(None)\n",
        "            sentiment_probs.append(None)\n",
        "    return sentiment_scores, sentiment_probs"
      ],
      "metadata": {
        "id": "1i0s753I9Pb6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Target Stock and News"
      ],
      "metadata": {
        "id": "Dko5LpLjE56A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stocks = ['AAPL', 'META', 'NVDA']\n",
        "related_terms = {\n",
        "    'AAPL': ['AAPL', 'Apple'],\n",
        "    'META': ['META', 'Metaverse'],\n",
        "    'NVDA': ['NVDA', 'NVIDIA'],\n",
        "}\n",
        "# company url names for Investing.com\n",
        "url_names = {\n",
        "    'AAPL': 'apple-computer-inc',\n",
        "    'META': 'facebook-inc',\n",
        "    'NVDA': 'nvidia-corp',\n",
        "}\n",
        "start = \"2022-01-01\"\n",
        "end = \"2024-01-01\""
      ],
      "metadata": {
        "id": "J8j5Yk8QE5mf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for stock in stocks:\n",
        "    csv = f\"/content/drive/My Drive/WPI/Senior Year/CS539 (ML)/{stock}_news.csv\"\n",
        "    df = pd.read_csv(csv)\n",
        "    print(len(df))\n",
        "    print(len(df[df.duplicated(['title']) == True]))\n",
        "    df = df.drop_duplicates(['title'])\n",
        "    print(len(df))\n",
        "    scores, probs = get_sentiment_results(df)\n",
        "    df['sentiment_score'] = scores\n",
        "    df['sentiment_probs'] = probs\n",
        "    df.to_csv(f\"/content/drive/My Drive/WPI/Senior Year/CS539 (ML)/{stock}_sentiment.csv\", index=False)"
      ],
      "metadata": {
        "id": "XE-B07bLEU3d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}